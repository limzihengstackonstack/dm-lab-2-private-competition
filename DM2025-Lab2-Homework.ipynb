{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:   Lim Zi Heng\n",
    "\n",
    "Student ID:  313708018 \n",
    "\n",
    "GitHub ID:  limzihengstackonstack\n",
    "\n",
    "Kaggle name: Lim Zi Heng  \n",
    "\n",
    "Kaggle private scoreboard snapshot: ![image.png](attachment:image.png)\n",
    "\n",
    "![pic_ranking.png](./pics/pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model Development \n",
    "\n",
    "\n",
    "1.1 Preprocessing Steps\n",
    "\n",
    "I applied several preprocessing operations to clean and normalize the social-media text data:\n",
    "\n",
    "Preprocessing Steps Applied\n",
    "\n",
    "Lowercasing\n",
    "Converted all text to lowercase to reduce vocabulary size.\n",
    "\n",
    "Remove URLs\n",
    "Eliminated links such as http://... or https://....\n",
    "\n",
    "Remove User Mentions\n",
    "Removed patterns like @username.\n",
    "\n",
    "Process Hashtags\n",
    "#happy  happy\n",
    "\n",
    "Remove Emojis + Special Characters\n",
    "Stripped non-alphanumeric characters.\n",
    "\n",
    "Normalize whitespace\n",
    "Convert sequences like \"this is good\"  \"this is good\".\n",
    "\n",
    "Created two cleaned versions\n",
    "\n",
    "clean_text: strong cleaning\n",
    "\n",
    "clean_text_soft: lighter cleaning (keeps emotional cues)\n",
    "\n",
    "These fields became the foundation for both classical models and transformer models.\n",
    "\n",
    "\n",
    "\n",
    "1.2 Feature Engineering Steps\n",
    "\n",
    "I used different feature representations depending on model type.\n",
    "\n",
    "\n",
    "\n",
    "A. TF-IDF Features (Classical ML)\n",
    "\n",
    "Word-level TF-IDF\n",
    "\n",
    "ngram: (1, 2)\n",
    "\n",
    "max_features = 20,000\n",
    "\n",
    "Captures meaningful phrases like very sad, feels happy\n",
    "\n",
    "Character-level TF-IDF\n",
    "\n",
    "ngram: (3, 5)\n",
    "\n",
    "Good for noisy user text (e.g., \"soooo gooood\")\n",
    "\n",
    "Stacked TF-IDF Matrix\n",
    "\n",
    "X_train: (38312, 20000)\n",
    "X_val:   (9578, 20000)\n",
    "\n",
    "\n",
    "This combined feature set was used for SVM, Logistic Regression, and ensembles.\n",
    "\n",
    "\n",
    "\n",
    "B. Transformer Features (DistilBERT)\n",
    "\n",
    "For DistilBERT, I used HuggingFace tokenization:\n",
    "\n",
    "Tokenizer: distilbert-base-uncased\n",
    "\n",
    "max_length = 96\n",
    "\n",
    "Padding to max length\n",
    "\n",
    "Truncation enabled\n",
    "\n",
    "Labels encoded with LabelEncoder\n",
    "\n",
    "Each processed sample contains:\n",
    "\n",
    "input_ids\n",
    "\n",
    "attention_mask\n",
    "\n",
    "labels (train/val only)\n",
    "\n",
    "This structure is compatible with the HuggingFace Trainer.\n",
    "\n",
    "\n",
    "\n",
    "1.3 Model Explanations\n",
    "\n",
    "A. Classical Models\n",
    "\n",
    "1. Logistic Regression\n",
    "\n",
    "Linear classifier using TF-IDF vectors\n",
    "\n",
    "Good baseline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Linear SVM\n",
    "\n",
    "Very strong for sparse high-dimensional data\n",
    "\n",
    "Tuned C = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Word + Char TF-IDF SVM\n",
    "\n",
    "Captures word meaning + character patterns\n",
    "\n",
    "Helps detect stretched emotional text (sooooo happy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. Ensemble Model (SVM + Logistic Regression)\n",
    "\n",
    "Averaged probability outputs\n",
    "\n",
    "Most stable classical model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "B. Neural Network Model (BiLSTM)\n",
    "\n",
    "Architecture:\n",
    "\n",
    "Embedding layer\n",
    "\n",
    "BiLSTM\n",
    "\n",
    "Dropout\n",
    "\n",
    "Dense output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "C. Transformer Model (DistilBERT)\n",
    "\n",
    "(In progress during development)\n",
    "\n",
    "I prepared a full fine-tuning pipeline using:\n",
    "\n",
    "DistilBERT backbone\n",
    "\n",
    "HuggingFace Trainer\n",
    "\n",
    "GPU acceleration\n",
    "\n",
    "Tokenized DatasetDict (train/val/test)\n",
    "\n",
    "Transformers understand context, sarcasm, and long-range dependencies.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Bonus Section (Optional: 5 pts)\n",
    "\n",
    "2.1 Different Experiments I Tried\n",
    "Preprocessing Variants\n",
    "\n",
    "Strong cleaning vs soft cleaning\n",
    "\n",
    "Emoji removal vs emoji retention\n",
    "\n",
    "Cleaning hashtags differently\n",
    "\n",
    "Feature Engineering Methods\n",
    "\n",
    "Word TF-IDF\n",
    "\n",
    "Character TF-IDF\n",
    "\n",
    "Combined Word + Char models\n",
    "\n",
    "Various n-gram ranges\n",
    "\n",
    "Different vocabulary sizes\n",
    "\n",
    "Model Trials\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Linear SVM (C tuning)\n",
    "\n",
    "Multinomial models\n",
    "\n",
    "Ensemble models\n",
    "\n",
    "BiLSTM neural network\n",
    "\n",
    "DistilBERT transformer\n",
    "\n",
    "CPU vs GPU performance tests\n",
    "\n",
    "Hyperparameter Tuning\n",
    "\n",
    "Batch size\n",
    "\n",
    "Learning rate\n",
    "\n",
    "Regularization (C, weight decay)\n",
    "\n",
    "Sequence length (BERT)\n",
    "\n",
    "Epoch count\n",
    "\n",
    "\n",
    "2.2 Insights I Gained\n",
    "\n",
    "Insight 1  TF-IDF + SVM is a Very Strong Baseline\n",
    "\n",
    "Outperforms many naive deep learning models.\n",
    "\n",
    "\n",
    "Insight 2  Character n-grams Help with Noisy Text\n",
    "\n",
    "Useful for:\n",
    "\n",
    "omggggg\n",
    "\n",
    "yaaay\n",
    "\n",
    "nooooooo\n",
    "\n",
    "\n",
    "Insight 3  Deep Learning Needs Pretrained Embeddings\n",
    "\n",
    "BiLSTM without pretrained embeddings performed worse than SVM.\n",
    "\n",
    "\n",
    "Insight 4  Transformers Require Careful Data Formatting\n",
    "\n",
    "I learned:\n",
    "\n",
    "label  labels\n",
    "\n",
    "Must remove raw text after tokenization\n",
    "\n",
    "Must use DatasetDict correctly\n",
    "\n",
    "\n",
    "Insight 5  GPU Makes a Huge Difference\n",
    "\n",
    "Training DistilBERT on CPU is unrealistic.\n",
    "GPU reduces training from hours to minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts (flattened): (64171, 2)\n",
      "    post_id                                               text\n",
      "0  0x61fc95  We got the ranch, loaded our guns and sat up t...\n",
      "1  0x35663e  I bet there is an army of married couples who ...\n",
      "2  0xc78afe                         This could only end badly.\n",
      "3  0x90089c  My sister squeezed a lime in her milk when she...\n",
      "4  0xaba820         and that got my head bobbing a little bit. \n",
      "\n",
      "ident:\n",
      "     post_id   type\n",
      "0  0x61fc95   test\n",
      "1  0x35663e  train\n",
      "2  0xc78afe  train\n",
      "3  0x90089c  train\n",
      "4  0xaba820   test \n",
      "\n",
      "emotion:\n",
      "     post_id emotion\n",
      "0  0x35663e     joy\n",
      "1  0xc78afe    fear\n",
      "2  0x90089c     joy\n",
      "3  0x2ffb63     joy\n",
      "4  0x989146     joy \n",
      "\n",
      "train_df: (47890, 4)\n",
      "test_df : (16281, 4) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>i bet there is an army of married couples who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>this could only end badly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>my sister squeezed a lime in her milk when she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x2ffb63</td>\n",
       "      <td>Thank you so much</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thank you so much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x989146</td>\n",
       "      <td>Stinks because ive been in this program for a ...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>stinks because ive been in this program for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id                                               text   type emotion  \\\n",
       "1  0x35663e  I bet there is an army of married couples who ...  train     joy   \n",
       "2  0xc78afe                         This could only end badly.  train    fear   \n",
       "3  0x90089c  My sister squeezed a lime in her milk when she...  train     joy   \n",
       "7  0x2ffb63                                Thank you so much  train     joy   \n",
       "9  0x989146  Stinks because ive been in this program for a ...  train     joy   \n",
       "\n",
       "                                          clean_text  \n",
       "1  i bet there is an army of married couples who ...  \n",
       "2                          this could only end badly  \n",
       "3  my sister squeezed a lime in her milk when she...  \n",
       "7                                  thank you so much  \n",
       "9  stinks because ive been in this program for a ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ---------- 1. LOAD AND FLATTEN JSON POSTS ----------\n",
    "\n",
    "raw_posts = pd.read_json(\"final_posts.json\")\n",
    "posts_flat = pd.json_normalize(raw_posts[\"root\"])\n",
    "\n",
    "posts = posts_flat.rename(columns={\n",
    "    \"_source.post.post_id\": \"post_id\",\n",
    "    \"_source.post.text\": \"text\"\n",
    "})[[\"post_id\", \"text\"]]\n",
    "\n",
    "print(\"posts (flattened):\", posts.shape)\n",
    "print(posts.head(), \"\\n\")\n",
    "\n",
    "\n",
    "# ---------- 2. LOAD IDENTIFICATION + EMOTION CSV ----------\n",
    "\n",
    "ident = pd.read_csv(\"data_identification.csv\")\n",
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "\n",
    "# force rename to match posts\n",
    "ident.rename(columns={\"id\": \"post_id\", \"split\": \"type\"}, inplace=True)\n",
    "emotion.rename(columns={\"id\": \"post_id\"}, inplace=True)\n",
    "\n",
    "print(\"ident:\\n\", ident.head(), \"\\n\")\n",
    "print(\"emotion:\\n\", emotion.head(), \"\\n\")\n",
    "\n",
    "\n",
    "# ---------- 3. MERGE INTO ONE DATAFRAME ----------\n",
    "\n",
    "df = posts.merge(ident, on=\"post_id\", how=\"left\")\n",
    "df = df.merge(emotion, on=\"post_id\", how=\"left\")  # only train rows have labels\n",
    "\n",
    "train_df = df[df[\"type\"] == \"train\"].copy()\n",
    "test_df  = df[df[\"type\"] == \"test\"].copy()\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "print(\"test_df :\", test_df.shape, \"\\n\")\n",
    "\n",
    "\n",
    "# ---------- 4. BASIC TEXT CLEANING ----------\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)\n",
    "    text = text.replace(\"#\", \" \")\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"]  = test_df[\"text\"].apply(clean_text)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 20000), (9578, 20000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = train_df[\"clean_text\"]\n",
    "y = train_df[\"emotion\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF with 12 grams (you can later try (1,3))\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\",\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec   = vectorizer.transform(X_val)\n",
    "\n",
    "X_train_vec.shape, X_val_vec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC C=0.5  -> val_acc=0.6005\n",
      "LinearSVC C=1.0  -> val_acc=0.5873\n",
      "LinearSVC C=2.0  -> val_acc=0.5716\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg C=1.0      -> val_acc=0.5884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg C=2.0      -> val_acc=0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg C=4.0      -> val_acc=0.5736\n",
      "\n",
      "Best model: LinearSVC_C0.5 val_acc= 0.6005429108373356\n",
      "\n",
      "Classification report for best model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.53      0.53      0.53      2139\n",
      "     disgust       0.29      0.05      0.09       237\n",
      "        fear       0.49      0.31      0.38       402\n",
      "         joy       0.67      0.83      0.74      4759\n",
      "     sadness       0.45      0.25      0.32       785\n",
      "    surprise       0.40      0.26      0.31      1256\n",
      "\n",
      "    accuracy                           0.60      9578\n",
      "   macro avg       0.47      0.37      0.40      9578\n",
      "weighted avg       0.57      0.60      0.57      9578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "models = {}\n",
    "\n",
    "# 1) Linear SVM with a few C values\n",
    "for C in [0.5, 1.0, 2.0]:\n",
    "    clf = LinearSVC(C=C)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    pred = clf.predict(X_val_vec)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    models[f\"LinearSVC_C{C}\"] = (acc, clf)\n",
    "    print(f\"LinearSVC C={C}  -> val_acc={acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2) Logistic Regression with a few C values\n",
    "for C in [1.0, 2.0, 4.0]:\n",
    "    logreg = LogisticRegression(\n",
    "        C=C,\n",
    "        max_iter=4000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        multi_class=\"ovr\",\n",
    "        solver=\"liblinear\",\n",
    "    )\n",
    "    logreg.fit(X_train_vec, y_train)\n",
    "    pred = logreg.predict(X_val_vec)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    models[f\"LogReg_C{C}\"] = (acc, logreg)\n",
    "    print(f\"LogReg C={C}      -> val_acc={acc:.4f}\")\n",
    "\n",
    "# pick best model\n",
    "best_name, (best_acc, best_model) = max(models.items(), key=lambda kv: kv[1][0])\n",
    "print(\"\\nBest model:\", best_name, \"val_acc=\", best_acc)\n",
    "\n",
    "# show detailed report of best model\n",
    "best_pred = best_model.predict(X_val_vec)\n",
    "print(\"\\nClassification report for best model:\\n\")\n",
    "print(classification_report(y_val, best_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id   emotion\n",
       "0  0x61fc95  surprise\n",
       "4  0xaba820       joy\n",
       "5  0x66e44d       joy\n",
       "6  0xc03cf5       joy\n",
       "8  0x02f65a       joy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ---------- 1. Rebuild the best model with its own params ----------\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# best_model is already fitted on train split.\n",
    "# We copy its hyperparameters and refit on ALL training data.\n",
    "if isinstance(best_model, LinearSVC):\n",
    "    final_model = LinearSVC(**best_model.get_params())\n",
    "elif isinstance(best_model, LogisticRegression):\n",
    "    final_model = LogisticRegression(**best_model.get_params())\n",
    "else:\n",
    "    raise ValueError(\"Unexpected best_model type:\", type(best_model))\n",
    "\n",
    "# ---------- 2. Fit vectorizer on ALL training data ----------\n",
    "\n",
    "X_full = train_df[\"clean_text\"]\n",
    "y_full = train_df[\"emotion\"]\n",
    "X_test = test_df[\"clean_text\"]\n",
    "\n",
    "X_full_vec = vectorizer.fit_transform(X_full)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# ---------- 3. Train final model on ALL training data ----------\n",
    "\n",
    "final_model.fit(X_full_vec, y_full)\n",
    "\n",
    "# ---------- 4. Predict on test and create submission ----------\n",
    "\n",
    "test_pred = final_model.predict(X_test_vec)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"post_id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"my_submission_strong_ml.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5872833576947171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.51      0.52      0.51      2139\n",
      "     disgust       0.21      0.06      0.10       237\n",
      "        fear       0.48      0.33      0.39       402\n",
      "         joy       0.68      0.81      0.74      4759\n",
      "     sadness       0.40      0.26      0.31       785\n",
      "    surprise       0.36      0.27      0.31      1256\n",
      "\n",
      "    accuracy                           0.59      9578\n",
      "   macro avg       0.44      0.37      0.39      9578\n",
      "weighted avg       0.56      0.59      0.57      9578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Train baseline model on train split\n",
    "model = LinearSVC(C=1.0)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 2) Evaluate on validation split\n",
    "y_val_pred = model.predict(X_val_vec)\n",
    "\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation accuracy:\", val_acc)\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id emotion\n",
       "0  0x61fc95    fear\n",
       "4  0xaba820     joy\n",
       "5  0x66e44d     joy\n",
       "6  0xc03cf5     joy\n",
       "8  0x02f65a     joy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Train final model on ALL training data\n",
    "X_full = train_df[\"clean_text\"]\n",
    "y_full = train_df[\"emotion\"]\n",
    "X_test = test_df[\"clean_text\"]\n",
    "\n",
    "X_full_vec = vectorizer.fit_transform(X_full)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "final_model = LinearSVC(C=1.0)\n",
    "final_model.fit(X_full_vec, y_full)\n",
    "\n",
    "# 4) Predict test labels\n",
    "test_pred = final_model.predict(X_test_vec)\n",
    "\n",
    "# 5) Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"post_id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"my_submission.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 60), (9578, 60))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Use clean_text\n",
    "texts = train_df[\"clean_text\"].astype(str).tolist()\n",
    "labels = train_df[\"emotion\"].tolist()\n",
    "\n",
    "# Encode labels to 0..3\n",
    "label_enc = LabelEncoder()\n",
    "y_all = label_enc.fit_transform(labels)\n",
    "\n",
    "# Train/val split (again, for NN)\n",
    "X_train_texts, X_val_texts, y_train_nn, y_val_nn = train_test_split(\n",
    "    texts, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "max_words = 30000   # vocab size\n",
    "max_len   = 60      # max tokens per tweet\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(X_train_texts)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_texts)\n",
    "X_val_seq   = tokenizer.texts_to_sequences(X_val_texts)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "X_val_pad   = pad_sequences(X_val_seq,   maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_train_pad.shape, X_val_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> \n",
       "\n",
       " bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m3,840,000\u001b[0m \n",
       "\n",
       " bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m98,816\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                         \u001b[38;5;34m390\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,947,462</span> (15.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,947,462\u001b[0m (15.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,947,462</span> (15.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,947,462\u001b[0m (15.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_words = 30000\n",
    "max_len   = 60\n",
    "num_classes = len(label_enc.classes_)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128),  # remove input_length\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Build explicitly so summary knows shapes\n",
    "model.build(input_shape=(None, max_len))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 - 13s - 86ms/step - accuracy: 0.4924 - loss: 1.3872 - val_accuracy: 0.5520 - val_loss: 1.2086\n",
      "Epoch 2/10\n",
      "150/150 - 10s - 70ms/step - accuracy: 0.5924 - loss: 1.1398 - val_accuracy: 0.5966 - val_loss: 1.1069\n",
      "Epoch 3/10\n",
      "150/150 - 11s - 71ms/step - accuracy: 0.6611 - loss: 0.9522 - val_accuracy: 0.6041 - val_loss: 1.1030\n",
      "Epoch 4/10\n",
      "150/150 - 11s - 70ms/step - accuracy: 0.7189 - loss: 0.8042 - val_accuracy: 0.5952 - val_loss: 1.1802\n",
      "Epoch 5/10\n",
      "150/150 - 10s - 70ms/step - accuracy: 0.7581 - loss: 0.6959 - val_accuracy: 0.5762 - val_loss: 1.2685\n",
      "Epoch 6/10\n",
      "150/150 - 10s - 70ms/step - accuracy: 0.7931 - loss: 0.6059 - val_accuracy: 0.5802 - val_loss: 1.4442\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train_nn,\n",
    "    validation_data=(X_val_pad, y_val_nn),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[es],\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 - 10s - 68ms/step - accuracy: 0.7226 - loss: 0.7884 - val_accuracy: 0.5934 - val_loss: 1.1832\n",
      "Epoch 2/10\n",
      "150/150 - 10s - 68ms/step - accuracy: 0.7583 - loss: 0.6953 - val_accuracy: 0.5835 - val_loss: 1.3018\n",
      "Epoch 3/10\n",
      "150/150 - 10s - 67ms/step - accuracy: 0.7875 - loss: 0.6113 - val_accuracy: 0.5701 - val_loss: 1.3217\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train_nn,\n",
    "    validation_data=(X_val_pad, y_val_nn),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[es],\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "NN validation accuracy: 0.5934433075798705\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.51      0.58      0.54      2139\n",
      "     disgust       0.00      0.00      0.00       237\n",
      "        fear       0.41      0.17      0.24       402\n",
      "         joy       0.72      0.78      0.75      4759\n",
      "     sadness       0.29      0.25      0.27       785\n",
      "    surprise       0.40      0.38      0.39      1256\n",
      "\n",
      "    accuracy                           0.59      9578\n",
      "   macro avg       0.39      0.36      0.37      9578\n",
      "weighted avg       0.57      0.59      0.58      9578\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_val_probs = model.predict(X_val_pad)\n",
    "y_val_pred  = np.argmax(y_val_probs, axis=1)\n",
    "\n",
    "print(\"NN validation accuracy:\", accuracy_score(y_val_nn, y_val_pred))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_val_nn, y_val_pred, target_names=label_enc.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.7213 - loss: 0.8105\n",
      "Epoch 2/2\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.7492 - loss: 0.7282\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  emotion\n",
       "0  0x61fc95      joy\n",
       "4  0xaba820  sadness\n",
       "5  0x66e44d      joy\n",
       "6  0xc03cf5      joy\n",
       "8  0x02f65a      joy"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Fit tokenizer on ALL training texts\n",
    "all_texts = train_df[\"clean_text\"].astype(str).tolist()\n",
    "all_labels = label_enc.transform(train_df[\"emotion\"])\n",
    "\n",
    "all_seq = tokenizer.texts_to_sequences(all_texts)\n",
    "all_pad = pad_sequences(all_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# 2) Re-train model on all data (you can keep previous weights, but simplest is new model)\n",
    "model_full = tf.keras.models.clone_model(model)\n",
    "model_full.build(input_shape=(None, max_len))\n",
    "model_full.set_weights(model.get_weights())  # start from previous best weights\n",
    "model_full.compile(optimizer=\"adam\",\n",
    "                   loss=\"sparse_categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_full.fit(\n",
    "    all_pad, all_labels,\n",
    "    epochs=2,   # few extra epochs on all data\n",
    "    batch_size=256,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# 3) Prepare test sequences\n",
    "test_texts = test_df[\"clean_text\"].astype(str).tolist()\n",
    "test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "test_pad = pad_sequences(test_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# 4) Predict and decode labels\n",
    "test_probs = model_full.predict(test_pad, batch_size=256)\n",
    "test_pred_ids = np.argmax(test_probs, axis=1)\n",
    "test_pred_labels = label_enc.inverse_transform(test_pred_ids)\n",
    "\n",
    "nn_submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred_labels\n",
    "})\n",
    "\n",
    "nn_submission.to_csv(\"my_submission_nn.csv\", index=False)\n",
    "nn_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_soft(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)\n",
    "    text = text.replace(\"#\", \" \")\n",
    "    # keep basic punctuation and emojis, just remove control chars\n",
    "    text = re.sub(r\"[\\r\\n\\t]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text_soft\"] = train_df[\"text\"].apply(clean_text_soft)\n",
    "test_df[\"clean_text_soft\"]  = test_df[\"text\"].apply(clean_text_soft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=40000,\n",
    "    ngram_range=(1, 3),            # include trigrams\n",
    "    stop_words=\"english\",\n",
    "    sublinear_tf=True,\n",
    "    min_df=3                        # ignore ultra-rare n-grams\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_features=30000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# WORD-LEVEL TF-IDF (13 grams)\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=40000,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# CHARACTER-LEVEL TF-IDF (35 char ngrams)\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_features=30000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 61068), (9578, 61068))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Word features\n",
    "X_train_w = word_vectorizer.fit_transform(X_train)\n",
    "X_val_w   = word_vectorizer.transform(X_val)\n",
    "\n",
    "# Character features\n",
    "X_train_c = char_vectorizer.fit_transform(X_train)\n",
    "X_val_c   = char_vectorizer.transform(X_val)\n",
    "\n",
    "# Combine word + char features\n",
    "X_train_vec = hstack([X_train_w, X_train_c])\n",
    "X_val_vec   = hstack([X_val_w, X_val_c])\n",
    "\n",
    "X_train_vec.shape, X_val_vec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs_svm = [0.2, 0.5, 1.0, 2.0]\n",
    "Cs_log = [0.5, 1.0, 2.0, 4.0]\n",
    "\n",
    "# keep the same loop, just more Cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# fit both models on full data\n",
    "encoder = LabelEncoder()\n",
    "y_full_int = encoder.fit_transform(y_full)\n",
    "\n",
    "svc = LinearSVC(C=0.5).fit(X_full_vec, y_full_int)\n",
    "logreg = LogisticRegression(\n",
    "    C=2.0, max_iter=4000, class_weight=\"balanced\",\n",
    "    n_jobs=-1, multi_class=\"ovr\", solver=\"liblinear\"\n",
    ").fit(X_full_vec, y_full_int)\n",
    "\n",
    "svc_logits   = svc.decision_function(X_test_vec)      # shape (N, 4)\n",
    "logreg_proba = logreg.predict_proba(X_test_vec)       # (N, 4)\n",
    "\n",
    "# convert SVC logits to pseudo-probabilities via softmax\n",
    "svc_proba = np.exp(svc_logits) / np.exp(svc_logits).sum(axis=1, keepdims=True)\n",
    "\n",
    "# weighted average\n",
    "proba_ensemble = 0.6 * svc_proba + 0.4 * logreg_proba\n",
    "pred_int = proba_ensemble.argmax(axis=1)\n",
    "pred_labels = encoder.inverse_transform(pred_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 - 11s - 75ms/step - accuracy: 0.7603 - loss: 0.6886 - val_accuracy: 0.5872 - val_loss: 1.3065\n",
      "Epoch 2/10\n",
      "150/150 - 11s - 75ms/step - accuracy: 0.7891 - loss: 0.6111 - val_accuracy: 0.5759 - val_loss: 1.4039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train_nn,\n",
    "    validation_data=(X_val_pad, y_val_nn),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[es],\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (word + char) + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_soft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>i bet there is an army of married couples who ...</td>\n",
       "      <td>i bet there is an army of married couples who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>this could only end badly</td>\n",
       "      <td>this could only end badly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>my sister squeezed a lime in her milk when she...</td>\n",
       "      <td>my sister squeezed a lime in her milk when she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thank you so much</td>\n",
       "      <td>thank you so much</td>\n",
       "      <td>thank you so much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stinks because ive been in this program for a ...</td>\n",
       "      <td>stinks because ive been in this program for a ...</td>\n",
       "      <td>stinks because ive been in this program for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "1  I bet there is an army of married couples who ...   \n",
       "2                         This could only end badly.   \n",
       "3  My sister squeezed a lime in her milk when she...   \n",
       "7                                Thank you so much   \n",
       "9  Stinks because ive been in this program for a ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "1  i bet there is an army of married couples who ...   \n",
       "2                          this could only end badly   \n",
       "3  my sister squeezed a lime in her milk when she...   \n",
       "7                                  thank you so much   \n",
       "9  stinks because ive been in this program for a ...   \n",
       "\n",
       "                                     clean_text_soft  \n",
       "1  i bet there is an army of married couples who ...  \n",
       "2                         this could only end badly.  \n",
       "3  my sister squeezed a lime in her milk when she...  \n",
       "7                                thank you so much  \n",
       "9  stinks because ive been in this program for a ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_soft(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)   # URLs\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)               # mentions\n",
    "    text = text.replace(\"#\", \" \")                   # keep hashtag words\n",
    "    text = re.sub(r\"[\\r\\n\\t]\", \" \", text)           # newlines  space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text_soft\"] = train_df[\"text\"].apply(clean_text_soft)\n",
    "test_df[\"clean_text_soft\"]  = test_df[\"text\"].apply(clean_text_soft)\n",
    "\n",
    "train_df[[\"text\", \"clean_text\", \"clean_text_soft\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 61487), (9578, 61487))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "TEXT_COL = \"clean_text_soft\"   # try \"clean_text\" vs \"clean_text_soft\" if you want to compare\n",
    "\n",
    "X = train_df[TEXT_COL]\n",
    "y = train_df[\"emotion\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------- word-level TF-IDF ----------\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=40000,\n",
    "    ngram_range=(1, 3),        # up to trigrams\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# ---------- character-level TF-IDF ----------\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_features=30000\n",
    ")\n",
    "\n",
    "# Fit on training, transform both train & val\n",
    "X_train_w = word_vectorizer.fit_transform(X_train)\n",
    "X_val_w   = word_vectorizer.transform(X_val)\n",
    "\n",
    "X_train_c = char_vectorizer.fit_transform(X_train)\n",
    "X_val_c   = char_vectorizer.transform(X_val)\n",
    "\n",
    "# Combine word + char features\n",
    "X_train_vec = hstack([X_train_w, X_train_c])\n",
    "X_val_vec   = hstack([X_val_w, X_val_c])\n",
    "\n",
    "X_train_vec.shape, X_val_vec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC C=0.2 -> val_acc=0.6375\n",
      "LinearSVC C=0.5 -> val_acc=0.6216\n",
      "LinearSVC C=1.0 -> val_acc=0.6048\n",
      "LinearSVC C=2.0 -> val_acc=0.5908\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg   C=0.5 -> val_acc=0.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg   C=1.0 -> val_acc=0.6129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg   C=2.0 -> val_acc=0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg   C=4.0 -> val_acc=0.6110\n",
      "\n",
      "Best model: LinearSVC_C0.2 val_acc= 0.6375026101482564\n",
      "\n",
      "Classification report for best model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.57      0.57      2139\n",
      "     disgust       0.42      0.07      0.12       237\n",
      "        fear       0.58      0.35      0.44       402\n",
      "         joy       0.69      0.86      0.77      4759\n",
      "     sadness       0.52      0.25      0.34       785\n",
      "    surprise       0.54      0.36      0.43      1256\n",
      "\n",
      "    accuracy                           0.64      9578\n",
      "   macro avg       0.55      0.41      0.44      9578\n",
      "weighted avg       0.62      0.64      0.61      9578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "models = {}\n",
    "\n",
    "# ---------- Linear SVM ----------\n",
    "for C in [0.2, 0.5, 1.0, 2.0]:\n",
    "    clf = LinearSVC(C=C)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    pred = clf.predict(X_val_vec)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    models[f\"LinearSVC_C{C}\"] = (acc, clf)\n",
    "    print(f\"LinearSVC C={C:<3} -> val_acc={acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "for C in [0.5, 1.0, 2.0, 4.0]:\n",
    "    logreg = LogisticRegression(\n",
    "        C=C,\n",
    "        max_iter=4000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        multi_class=\"ovr\",\n",
    "        solver=\"liblinear\",\n",
    "    )\n",
    "    logreg.fit(X_train_vec, y_train)\n",
    "    pred = logreg.predict(X_val_vec)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    models[f\"LogReg_C{C}\"] = (acc, logreg)\n",
    "    print(f\"LogReg   C={C:<3} -> val_acc={acc:.4f}\")\n",
    "\n",
    "# ---------- pick best ----------\n",
    "best_name, (best_acc, best_model) = max(models.items(), key=lambda kv: kv[1][0])\n",
    "print(\"\\nBest model:\", best_name, \"val_acc=\", best_acc)\n",
    "\n",
    "best_pred = best_model.predict(X_val_vec)\n",
    "print(\"\\nClassification report for best model:\\n\")\n",
    "print(classification_report(y_val, best_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id emotion\n",
       "0  0x61fc95     joy\n",
       "4  0xaba820     joy\n",
       "5  0x66e44d     joy\n",
       "6  0xc03cf5     joy\n",
       "8  0x02f65a     joy"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ---------- Rebuild same best model ----------\n",
    "if isinstance(best_model, LinearSVC):\n",
    "    final_model = LinearSVC(**best_model.get_params())\n",
    "elif isinstance(best_model, LogisticRegression):\n",
    "    final_model = LogisticRegression(**best_model.get_params())\n",
    "else:\n",
    "    raise ValueError(\"Unexpected best_model type\", type(best_model))\n",
    "\n",
    "# ---------- Fit vectorizers on ALL train text ----------\n",
    "X_full = train_df[TEXT_COL]\n",
    "y_full = train_df[\"emotion\"]\n",
    "X_test_texts = test_df[TEXT_COL]\n",
    "\n",
    "X_full_w = word_vectorizer.fit_transform(X_full)\n",
    "X_full_c = char_vectorizer.fit_transform(X_full)\n",
    "X_full_vec = hstack([X_full_w, X_full_c])\n",
    "\n",
    "X_test_w = word_vectorizer.transform(X_test_texts)\n",
    "X_test_c = char_vectorizer.transform(X_test_texts)\n",
    "X_test_vec = hstack([X_test_w, X_test_c])\n",
    "\n",
    "# ---------- Train final model ----------\n",
    "final_model.fit(X_full_vec, y_full)\n",
    "\n",
    "# ---------- Predict on test ----------\n",
    "test_pred = final_model.predict(X_test_vec)\n",
    "\n",
    "submission_wc = pd.DataFrame({\n",
    "    \"post_id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred\n",
    "})\n",
    "\n",
    "submission_wc.to_csv(\"my_submission_word_char_tfidf.csv\", index=False)\n",
    "submission_wc.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def run_config(\n",
    "    name,\n",
    "    text_col=\"clean_text_soft\",\n",
    "    use_char=True,\n",
    "    word_ngram=(1, 3),\n",
    "    word_max_features=40000,\n",
    "    stop_words=\"english\",\n",
    "    C=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a LinearSVC on a given text column + TF-IDF settings,\n",
    "    return validation accuracy and the fitted objects.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"text_col={text_col}, use_char={use_char}, word_ngram={word_ngram}, \"\n",
    "          f\"word_max_features={word_max_features}, C={C}\")\n",
    "\n",
    "    X = train_df[text_col]\n",
    "    y = train_df[\"emotion\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # word-level TF-IDF\n",
    "    word_vectorizer = TfidfVectorizer(\n",
    "        max_features=word_max_features,\n",
    "        ngram_range=word_ngram,\n",
    "        stop_words=stop_words,\n",
    "        sublinear_tf=True,\n",
    "        min_df=2,\n",
    "    )\n",
    "\n",
    "    X_train_w = word_vectorizer.fit_transform(X_train)\n",
    "    X_val_w   = word_vectorizer.transform(X_val)\n",
    "\n",
    "    if use_char:\n",
    "        # char-level TF-IDF\n",
    "        char_vectorizer = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=5,\n",
    "            max_features=30000,\n",
    "        )\n",
    "        X_train_c = char_vectorizer.fit_transform(X_train)\n",
    "        X_val_c   = char_vectorizer.transform(X_val)\n",
    "\n",
    "        X_train_vec = hstack([X_train_w, X_train_c])\n",
    "        X_val_vec   = hstack([X_val_w, X_val_c])\n",
    "    else:\n",
    "        char_vectorizer = None\n",
    "        X_train_vec = X_train_w\n",
    "        X_val_vec   = X_val_w\n",
    "\n",
    "    model = LinearSVC(C=C)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_val_pred = model.predict(X_val_vec)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"val_acc = {acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"acc\": acc,\n",
    "        \"text_col\": text_col,\n",
    "        \"use_char\": use_char,\n",
    "        \"word_ngram\": word_ngram,\n",
    "        \"word_max_features\": word_max_features,\n",
    "        \"stop_words\": stop_words,\n",
    "        \"C\": C,\n",
    "        \"word_vectorizer\": word_vectorizer,\n",
    "        \"char_vectorizer\": char_vectorizer,\n",
    "        \"model\": model,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== soft + word1-3 + char + C0.5 ===\n",
      "text_col=clean_text_soft, use_char=True, word_ngram=(1, 3), word_max_features=40000, C=0.5\n",
      "val_acc = 0.6216\n",
      "\n",
      "=== soft + word1-3 + char + C0.2 ===\n",
      "text_col=clean_text_soft, use_char=True, word_ngram=(1, 3), word_max_features=40000, C=0.2\n",
      "val_acc = 0.6375\n",
      "\n",
      "=== soft + word1-3 + char + C1.0 ===\n",
      "text_col=clean_text_soft, use_char=True, word_ngram=(1, 3), word_max_features=40000, C=1.0\n",
      "val_acc = 0.6048\n",
      "\n",
      "=== soft + word1-3 + char + C2.0 ===\n",
      "text_col=clean_text_soft, use_char=True, word_ngram=(1, 3), word_max_features=40000, C=2.0\n",
      "val_acc = 0.5908\n",
      "\n",
      "=== soft + word1-3 word-only + C0.5 ===\n",
      "text_col=clean_text_soft, use_char=False, word_ngram=(1, 3), word_max_features=50000, C=0.5\n",
      "val_acc = 0.5972\n",
      "\n",
      "=== soft + word1-3 word-only + C1.0 ===\n",
      "text_col=clean_text_soft, use_char=False, word_ngram=(1, 3), word_max_features=50000, C=1.0\n",
      "val_acc = 0.5851\n",
      "\n",
      "=== soft + word1-3 word-only + C2.0 ===\n",
      "text_col=clean_text_soft, use_char=False, word_ngram=(1, 3), word_max_features=50000, C=2.0\n",
      "val_acc = 0.5688\n",
      "\n",
      "=== hardclean + word1-3 word-only + C0.5 ===\n",
      "text_col=clean_text, use_char=False, word_ngram=(1, 3), word_max_features=50000, C=0.5\n",
      "val_acc = 0.5997\n",
      "\n",
      "=== hardclean + word1-3 word-only + C1.0 ===\n",
      "text_col=clean_text, use_char=False, word_ngram=(1, 3), word_max_features=50000, C=1.0\n",
      "val_acc = 0.5869\n",
      "soft + word1-3 + char + C0.2             val_acc=0.6375\n",
      "soft + word1-3 + char + C0.5             val_acc=0.6216\n",
      "soft + word1-3 + char + C1.0             val_acc=0.6048\n",
      "hardclean + word1-3 word-only + C0.5     val_acc=0.5997\n",
      "soft + word1-3 word-only + C0.5          val_acc=0.5972\n",
      "soft + word1-3 + char + C2.0             val_acc=0.5908\n",
      "hardclean + word1-3 word-only + C1.0     val_acc=0.5869\n",
      "soft + word1-3 word-only + C1.0          val_acc=0.5851\n",
      "soft + word1-3 word-only + C2.0          val_acc=0.5688\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# 1) your current good setting (baseline)\n",
    "results.append(run_config(\n",
    "    name=\"soft + word1-3 + char + C0.5\",\n",
    "    text_col=\"clean_text_soft\",\n",
    "    use_char=True,\n",
    "    word_ngram=(1, 3),\n",
    "    word_max_features=40000,\n",
    "    C=0.5,\n",
    "))\n",
    "\n",
    "# 2) same but stronger regularization\n",
    "for C_val in [0.2, 1.0, 2.0]:\n",
    "    results.append(run_config(\n",
    "        name=f\"soft + word1-3 + char + C{C_val}\",\n",
    "        text_col=\"clean_text_soft\",\n",
    "        use_char=True,\n",
    "        word_ngram=(1, 3),\n",
    "        word_max_features=40000,\n",
    "        C=C_val,\n",
    "    ))\n",
    "\n",
    "# 3) word-only (sometimes better than word+char)\n",
    "for C_val in [0.5, 1.0, 2.0]:\n",
    "    results.append(run_config(\n",
    "        name=f\"soft + word1-3 word-only + C{C_val}\",\n",
    "        text_col=\"clean_text_soft\",\n",
    "        use_char=False,\n",
    "        word_ngram=(1, 3),\n",
    "        word_max_features=50000,\n",
    "        C=C_val,\n",
    "    ))\n",
    "\n",
    "# 4) try original cleaning vs soft\n",
    "for C_val in [0.5, 1.0]:\n",
    "    results.append(run_config(\n",
    "        name=f\"hardclean + word1-3 word-only + C{C_val}\",\n",
    "        text_col=\"clean_text\",   # your original aggressive cleaning\n",
    "        use_char=False,\n",
    "        word_ngram=(1, 3),\n",
    "        word_max_features=50000,\n",
    "        C=C_val,\n",
    "    ))\n",
    "\n",
    "# show all\n",
    "for r in sorted(results, key=lambda x: x[\"acc\"], reverse=True):\n",
    "    print(f'{r[\"name\"]:<40} val_acc={r[\"acc\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('soft + word1-3 + char + C0.2', 0.6375026101482564)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = max(results, key=lambda x: x[\"acc\"])\n",
    "best[\"name\"], best[\"acc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best config: soft + word1-3 + char + C0.2 val_acc= 0.6375026101482564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id emotion\n",
       "0  0x61fc95     joy\n",
       "4  0xaba820     joy\n",
       "5  0x66e44d     joy\n",
       "6  0xc03cf5     joy\n",
       "8  0x02f65a     joy"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "best = max(results, key=lambda x: x[\"acc\"])\n",
    "print(\"Using best config:\", best[\"name\"], \"val_acc=\", best[\"acc\"])\n",
    "\n",
    "TEXT_COL = best[\"text_col\"]\n",
    "use_char = best[\"use_char\"]\n",
    "word_ngram = best[\"word_ngram\"]\n",
    "word_max_features = best[\"word_max_features\"]\n",
    "stop_words = best[\"stop_words\"]\n",
    "C = best[\"C\"]\n",
    "\n",
    "# ---------- Rebuild vectorizers on ALL training text ----------\n",
    "X_full = train_df[TEXT_COL]\n",
    "y_full = train_df[\"emotion\"]\n",
    "X_test_texts = test_df[TEXT_COL]\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=word_max_features,\n",
    "    ngram_range=word_ngram,\n",
    "    stop_words=stop_words,\n",
    "    sublinear_tf=True,\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "X_full_w = word_vectorizer.fit_transform(X_full)\n",
    "X_test_w = word_vectorizer.transform(X_test_texts)\n",
    "\n",
    "if use_char:\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(3, 5),\n",
    "        min_df=5,\n",
    "        max_features=30000,\n",
    "    )\n",
    "    X_full_c = char_vectorizer.fit_transform(X_full)\n",
    "    X_test_c = char_vectorizer.transform(X_test_texts)\n",
    "\n",
    "    X_full_vec = hstack([X_full_w, X_full_c])\n",
    "    X_test_vec = hstack([X_test_w, X_test_c])\n",
    "else:\n",
    "    X_full_vec = X_full_w\n",
    "    X_test_vec = X_test_w\n",
    "\n",
    "# ---------- Train final SVM ----------\n",
    "final_model = LinearSVC(C=C)\n",
    "final_model.fit(X_full_vec, y_full)\n",
    "\n",
    "# ---------- Predict & save submission ----------\n",
    "test_pred = final_model.predict(X_test_vec)\n",
    "submission_best = pd.DataFrame({\n",
    "    \"post_id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred\n",
    "})\n",
    "\n",
    "submission_path = \"my_submission_best_tuned_svm.csv\"\n",
    "submission_best.to_csv(submission_path, index=False)\n",
    "submission_best.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble (SVM + LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47890, 70000), (16281, 70000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "TEXT_COL = \"clean_text_soft\"   # change if you found another better one\n",
    "\n",
    "X_full_text = train_df[TEXT_COL]\n",
    "y_full      = train_df[\"emotion\"]\n",
    "X_test_text = test_df[TEXT_COL]\n",
    "\n",
    "# word-level TF-IDF\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=40000,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=\"english\",\n",
    "    sublinear_tf=True,\n",
    "    min_df=2,\n",
    ")\n",
    "X_full_w = word_vectorizer.fit_transform(X_full_text)\n",
    "X_test_w = word_vectorizer.transform(X_test_text)\n",
    "\n",
    "# char-level TF-IDF\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_features=30000,\n",
    ")\n",
    "X_full_c = char_vectorizer.fit_transform(X_full_text)\n",
    "X_test_c = char_vectorizer.transform(X_test_text)\n",
    "\n",
    "X_full_vec = hstack([X_full_w, X_full_c])\n",
    "X_test_vec = hstack([X_test_w, X_test_c])\n",
    "\n",
    "X_full_vec.shape, X_test_vec.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble w_svm=0.3 -> val_acc=0.6204\n",
      "Ensemble w_svm=0.5 -> val_acc=0.6247\n",
      "Ensemble w_svm=0.7 -> val_acc=0.6285\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# encode labels to 0..K-1\n",
    "le = LabelEncoder()\n",
    "y_full_int = le.fit_transform(y_full)\n",
    "\n",
    "# split off a small validation set JUST to tune ensemble weights\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_full_vec, y_full_int, test_size=0.15, random_state=42, stratify=y_full_int\n",
    ")\n",
    "\n",
    "# ---- 1. SVM ----\n",
    "C_svm = 0.5  # or use the C that worked best before\n",
    "svm = LinearSVC(C=C_svm)\n",
    "svm.fit(X_tr, y_tr)\n",
    "\n",
    "# decision_function -> logits\n",
    "svm_val_logits = svm.decision_function(X_val)   # shape (N, K)\n",
    "\n",
    "# softmax to get pseudo-probabilities\n",
    "svm_val_exp = np.exp(svm_val_logits - svm_val_logits.max(axis=1, keepdims=True))\n",
    "svm_val_proba = svm_val_exp / svm_val_exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "# ---- 2. Logistic Regression ----\n",
    "C_log = 2.0  # you can tune this, but 2.0 is often good\n",
    "logreg = LogisticRegression(\n",
    "    C=C_log,\n",
    "    max_iter=4000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    multi_class=\"ovr\",\n",
    "    solver=\"liblinear\",\n",
    ")\n",
    "logreg.fit(X_tr, y_tr)\n",
    "\n",
    "log_val_proba = logreg.predict_proba(X_val)     # shape (N, K)\n",
    "\n",
    "# ---- 3. Try a few ensemble weights ----\n",
    "weights = [0.3, 0.5, 0.7]  # weight on SVM (1-w on LogReg)\n",
    "\n",
    "for w in weights:\n",
    "    proba_ens = w * svm_val_proba + (1 - w) * log_val_proba\n",
    "    y_val_pred = proba_ens.argmax(axis=1)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Ensemble w_svm={w:.1f} -> val_acc={acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id emotion\n",
       "0  0x61fc95     joy\n",
       "4  0xaba820     joy\n",
       "5  0x66e44d     joy\n",
       "6  0xc03cf5     joy\n",
       "8  0x02f65a   anger"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain on ALL training data\n",
    "svm = LinearSVC(C=C_svm)\n",
    "svm.fit(X_full_vec, y_full_int)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=C_log,\n",
    "    max_iter=4000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    multi_class=\"ovr\",\n",
    "    solver=\"liblinear\",\n",
    ")\n",
    "logreg.fit(X_full_vec, y_full_int)\n",
    "\n",
    "# predict probabilities on test\n",
    "svm_test_logits = svm.decision_function(X_test_vec)\n",
    "svm_test_exp = np.exp(svm_test_logits - svm_test_logits.max(axis=1, keepdims=True))\n",
    "svm_test_proba = svm_test_exp / svm_test_exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "log_test_proba = logreg.predict_proba(X_test_vec)\n",
    "\n",
    "w_svm = 0.7   # put your best weight here\n",
    "proba_test_ens = w_svm * svm_test_proba + (1 - w_svm) * log_test_proba\n",
    "\n",
    "test_pred_int = proba_test_ens.argmax(axis=1)\n",
    "test_pred_labels = le.inverse_transform(test_pred_int)\n",
    "\n",
    "submission_ens = pd.DataFrame({\n",
    "    \"id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred_labels\n",
    "})\n",
    "\n",
    "submission_ens.to_csv(\"my_submission_svm_logreg_ensemble.csv\", index=False)\n",
    "submission_ens.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\btlim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'anger': np.int64(0), 'disgust': np.int64(1), 'fear': np.int64(2), 'joy': np.int64(3), 'sadness': np.int64(4), 'surprise': np.int64(5)}\n",
      "(43101, 7) (4789, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['post_id', 'clean_text_soft', 'label'],\n",
       "        num_rows: 43101\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['post_id', 'clean_text_soft', 'label'],\n",
       "        num_rows: 4789\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['post_id', 'clean_text_soft'],\n",
       "        num_rows: 16281\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use your cleaned column\n",
    "TEXT_COL = \"clean_text_soft\"   # or \"clean_text\" or \"text\" if you want to compare\n",
    "\n",
    "# 1. Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df = train_df.copy()\n",
    "train_df[\"label\"] = label_encoder.fit_transform(train_df[\"emotion\"])\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(\"Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "# 2. Train/validation split (e.g., 90% / 10%)\n",
    "train_split, val_split = train_test_split(\n",
    "    train_df, test_size=0.1, random_state=42, stratify=train_df[\"label\"]\n",
    ")\n",
    "\n",
    "print(train_split.shape, val_split.shape)\n",
    "\n",
    "# 3. Create HuggingFace datasets\n",
    "hf_train = Dataset.from_pandas(train_split[[\"post_id\", TEXT_COL, \"label\"]], preserve_index=False)\n",
    "hf_val   = Dataset.from_pandas(val_split[[\"post_id\", TEXT_COL, \"label\"]],   preserve_index=False)\n",
    "hf_test  = Dataset.from_pandas(test_df[[\"post_id\", TEXT_COL]],             preserve_index=False)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    \"train\": hf_train,\n",
    "    \"validation\": hf_val,\n",
    "    \"test\": hf_test,\n",
    "})\n",
    "\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 43101/43101 [00:01<00:00, 23375.21 examples/s]\n",
      "Map: 100%|| 4789/4789 [00:00<00:00, 29583.90 examples/s]\n",
      "Map: 100%|| 16281/16281 [00:00<00:00, 28585.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train columns: ['labels', 'input_ids', 'attention_mask']\n",
      "validation columns: ['labels', 'input_ids', 'attention_mask']\n",
      "test columns: ['input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_length = 96  # or 128 if you want\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[TEXT_COL],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "# 1. Tokenize all splits\n",
    "tokenized_datasets = datasets.map(tokenize_batch, batched=True)\n",
    "\n",
    "# 2. Remove text / post_id if they exist, but KEEP label\n",
    "cols_to_drop = [TEXT_COL, \"post_id\"]\n",
    "\n",
    "for split in tokenized_datasets.keys():\n",
    "    existing = [c for c in cols_to_drop if c in tokenized_datasets[split].column_names]\n",
    "    tokenized_datasets[split] = tokenized_datasets[split].remove_columns(existing)\n",
    "\n",
    "# 3. Rename label -> labels ONLY on splits that actually have label\n",
    "for split in tokenized_datasets.keys():\n",
    "    if \"label\" in tokenized_datasets[split].column_names:\n",
    "        tokenized_datasets[split] = tokenized_datasets[split].rename_column(\"label\", \"labels\")\n",
    "\n",
    "# 4. Set PyTorch format\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Sanity check\n",
    "for split in tokenized_datasets.keys():\n",
    "    print(split, \"columns:\", tokenized_datasets[split].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_macro,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btlim\\AppData\\Local\\Temp\\ipykernel_2348\\1096112518.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 3   # try 45 later if you have time/GPU\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-emotion\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    logging_dir=\"./logs-distilbert\",  # where to save logs\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4041' max='4041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4041/4041 08:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.901300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.857700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.740100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.708400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.638800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.556500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.530600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.531900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0163525342941284,\n",
       " 'eval_accuracy': 0.6702860722489037,\n",
       " 'eval_f1_macro': 0.5276130312540387,\n",
       " 'eval_runtime': 5.5872,\n",
       " 'eval_samples_per_second': 857.145,\n",
       " 'eval_steps_per_second': 26.847,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "trainer.save_model()  # saves best model to output_dir\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4041' max='4041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4041/4041 08:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.543800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.541900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.179500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6039613485336304,\n",
       " 'eval_accuracy': 0.6418876592190437,\n",
       " 'eval_f1_macro': 0.49354993602416924,\n",
       " 'eval_runtime': 5.4795,\n",
       " 'eval_samples_per_second': 873.989,\n",
       " 'eval_steps_per_second': 27.375,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "trainer.save_model()  # saves best model to output_dir\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trainer's best model\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "test_logits = predictions.predictions\n",
    "test_pred_ids = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "# Decode back to emotion labels\n",
    "test_pred_labels = label_encoder.inverse_transform(test_pred_ids)\n",
    "\n",
    "submission_distilbert = pd.DataFrame({\n",
    "    \"id\": test_df[\"post_id\"],\n",
    "    \"emotion\": test_pred_labels,\n",
    "})\n",
    "\n",
    "submission_distilbert.head()\n",
    "submission_distilbert.to_csv(\"my_submission_distilbert.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
